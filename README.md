# Extended OpenAI Conversation (EOC) for Home Assistant

A maintained fork of **Extended OpenAI Conversation** that works with the **current Home Assistant**, the **OpenAI Python SDK 1.x**, and supports **reasoning‚Äëclass models** via the **Responses API** (future‚Äëfriendly beyond GPT‚Äë5). Designed to plug directly into **Assist** (voice & text) with the correct response shape and optional memory scaffolding **off by default**.

> Upstream (reference): https://github.com/jekalmin/extended_openai_conversation  
> This fork (install via HACS): https://github.com/Da3dalusCode/extended_openai_conversation

---

## Features

- üîä **Assist integration** (voice & text): returns a valid `ConversationResult` and supports `continue_conversation`.
- üß† **Reasoning‚Äëclass models** (e.g., GPT‚Äë5 series, o‚Äëseries) through the **Responses API**, including `reasoning: { effort: ... }`.
- üí¨ **Standard models** through **Chat Completions** with `temperature` and `top_p`.
- üß© **Auto strategy** chooses the right API based on the model.
- üß± Memory/RAG scaffolding kept in the code but **OFF by default** (no external calls unless you wire it up).
- üîê Works with OpenAI or **OpenAI‚Äëcompatible** (including **Azure OpenAI**).

---

## Requirements

- Home Assistant **2024.6.0** or newer (recommended).
- An OpenAI API key (or Azure OpenAI key + endpoint + API version).
- HACS installed.

---

## Install (HACS)

1. In **HACS ‚Üí Integrations**, add this repository as a **Custom repository** (if not using the default list):  
   `https://github.com/Da3dalusCode/extended_openai_conversation`
2. Install the integration.
3. **Restart Home Assistant.**
4. Go to **Settings ‚Üí Devices & Services ‚Üí Add Integration ‚Üí ‚ÄúExtended OpenAI Conversation‚Äù**.
5. On the first screen, enter:
   - **API Key** (required)
   - **Base URL** (optional, required for Azure or other compatible servers)
   - **API Version** (Azure only)
   - **Organization** (optional)
   - **Default model** (e.g., `gpt-4o-mini`)

After creation, open **Options** to fine‚Äëtune behavior.

---

## Options

- **Model**  
- **API Strategy**: `auto` (recommended), `force_chat`, `force_responses`  
- **Reasoning Effort** (reasoning models): `minimal | low | medium | high`  
- **Max Output Tokens** (mapped to `max_tokens`, `max_completion_tokens`, or `max_output_tokens` automatically)  
- **Temperature** / **Top‚Äëp** (applied **only** to non‚Äëreasoning models)  
- **System Prompt** (optional)

> **Important:** Reasoning models reject sampling parameters like `temperature` / `top_p`. This integration automatically omits them when using reasoning models.

---

## Azure OpenAI

- Set **Base URL** to your Azure endpoint (e.g., `https://YOUR_RESOURCE_NAME.openai.azure.com`).
- Set **API Version** (e.g., `2024-12-01-preview`).
- The **model** you specify should be the **deployment name** in Azure.

---

## Assist Tips

- ‚ÄúPrefer local handling‚Äù is configured in your **Voice Assistant** and is not modified by this integration.
- `continue_conversation` is set automatically when the assistant‚Äôs reply contains a follow‚Äëup question.

---

## Troubleshooting

- **Can‚Äôt find the integration after install?** Restart Home Assistant, clear browser cache, and check **Logs**.
- **Invalid handler / migration errors?** Ensure you‚Äôve restarted after installing/updating in HACS.
- **Reasoning model errors?** Use the **Responses API** (default in `auto`) and set **Reasoning Effort**. Do not set temperature/top‚Äëp for reasoning models.

---

## Credits

- Original project: **jekalmin/extended_openai_conversation**
- This fork: **Da3dalusCode** ‚Äî adds Responses API, reasoning support, and current HA compatibility.

